{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91875\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import file and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=open('speeches.txt','rt',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin=text.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin=fin.replace('\\n', '')\n",
    "fin=fin.replace('.','. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen=sent_tokenize(fin)\n",
    "text.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=[]\n",
    "for i in sen:\n",
    "    final.append('<s> '+i.replace('.','').replace('?','').replace(',','').replace(' - ','')+' </s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest = train_test_split(final, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-grams listing and MLEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "big=dict()\n",
    "n = 2\n",
    "bc=0\n",
    "for sen in xTrain:\n",
    "    bigrams = ngrams(sen.split(), n)\n",
    "    for x in bigrams:\n",
    "        if(x not in big):\n",
    "            big[x]=1\n",
    "        else:\n",
    "            big[x]+=1\n",
    "        bc=bc+1       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri=dict()\n",
    "n = 3\n",
    "tc=0\n",
    "for sen in xTrain:\n",
    "    trigrams = ngrams(sen.split(), n)\n",
    "    for x in trigrams:\n",
    "        if(x not in tri):\n",
    "            tri[x]=1\n",
    "        else:\n",
    "            tri[x]=tri[x]+1\n",
    "        tc=tc+1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni=dict()\n",
    "n = 1\n",
    "uc=0\n",
    "for sen in xTrain:\n",
    "    unigrams = ngrams(sen.split(), n)\n",
    "    for x in unigrams:\n",
    "        if(x[-1]=='.'):\n",
    "            x=x[:-2]\n",
    "        if(x not in uni):\n",
    "            uni[x]=1\n",
    "        else:\n",
    "            uni[x]=uni[x]+1\n",
    "        uc=uc+1    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad=dict()\n",
    "n = 4\n",
    "qc=0\n",
    "for sen in xTrain:\n",
    "    quadgrams = ngrams(sen.split(), n)\n",
    "    for x in quadgrams:\n",
    "        if(x not in quad):\n",
    "            quad[x]=1\n",
    "        else:\n",
    "            quad[x]=quad[x]+1\n",
    "        qc=qc+1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162132, 148583, 135034, 121899)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uc,bc,tc,qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8043, 50617, 90373, 103141)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uni),len(big),len(tri),len(quad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLEB=dict()\n",
    "for i in big:\n",
    "    MLEB[i]=big[i]/uni[i[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLET=dict()\n",
    "for i in tri:\n",
    "    MLET[i]=tri[i]/big[i[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLEQ=dict()\n",
    "for i in quad:\n",
    "    MLEQ[i]=quad[i]/tri[i[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLEU=dict()\n",
    "for i in uni:\n",
    "    MLEU[i]=uni[i]/uc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-gram Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_first(gram,n):\n",
    "    x=['<s>']\n",
    "    b=[]\n",
    "    c=[]\n",
    "    for i in range(n-2):\n",
    "        x=list(x)\n",
    "        keys, values = zip(*gram[i+1].items()) \n",
    "        values=list(values)\n",
    "        keys=list(keys)\n",
    "        for j in keys:\n",
    "            l=list(j)\n",
    "            if(l[:i+1]==x):\n",
    "                c.append(gram[i+1][j])\n",
    "                b.append(j)\n",
    "#         print(b,c)\n",
    "        array=np.random.multinomial(1 , c , size=1)\n",
    "        for k in range(len(array[0])):\n",
    "            if(array[0][k]==1):\n",
    "#                 print(str(b[k]),end=' ')\n",
    "                x=b[k]\n",
    "        b=[]\n",
    "        c=[]\n",
    "    return(list(x))\n",
    "def generator(gram,n,m):\n",
    "#     keys, values = zip(*gram[n-2].items()) \n",
    "#     values=list(values)\n",
    "#     x='<s>'\n",
    "#     b=[]\n",
    "#     c=[]\n",
    "#     for j in keys:\n",
    "#         if(j[0]==x):\n",
    "#             c.append(gram[n-2][j])\n",
    "#             b.append(j)\n",
    "#     c=np.array(c)\n",
    "#     c=c/sum(c)        \n",
    "#     array=np.random.multinomial(1 , c , size=1)\n",
    "#     for k in range(len(array[0])):\n",
    "#         if(array[0][k]==1):\n",
    "#             print(str(b[k][:n-1]),end=' ')\n",
    "#             x=b[k] \n",
    "    if(n==1):\n",
    "        keys, values = zip(*MLEU.items()) \n",
    "        values=list(values)\n",
    "        array=np.random.multinomial(1 , values , size=m)\n",
    "        print('<s>',end=' ')\n",
    "        for i in array:\n",
    "            for j in range(len(keys)):\n",
    "                if(i[j]==1):\n",
    "                    if(keys[j][0]=='</s>'):\n",
    "                        print(str(keys[j][0]),end=' ')\n",
    "                        return\n",
    "                    print(str(keys[j][0]),end=' ')\n",
    "        return\n",
    "    x=predict_first(gram,n)\n",
    "    b=[]\n",
    "    c=[]\n",
    "    keys, values = zip(*gram[n-1].items()) \n",
    "    values=list(values)\n",
    "    keys=list(keys)\n",
    "    print(*x,end=' ')\n",
    "    for i in range(m):\n",
    "        s=0\n",
    "        for j in keys:\n",
    "            l=list(j)\n",
    "#             print(l[:n-1],x)\n",
    "            if(l[:n-1]==x):\n",
    "                c.append(gram[n-1][j])\n",
    "                b.append(j)\n",
    "#                 print(j,x,\"Match\")\n",
    "                s=1\n",
    "        if(s==0):\n",
    "            break\n",
    "        array=np.random.multinomial(1 , c , size=1)\n",
    "        for k in range(len(array[0])):\n",
    "            if(array[0][k]==1):\n",
    "                print((list(b[k]))[-1],end=' ')\n",
    "                x=b[k][1:]\n",
    "        x=list(x)\n",
    "        c=[]\n",
    "        b=[]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram\n",
      "<s> on not We’re We’re </s> \n",
      "Bigram\n",
      "<s> When the magazines no lobbyist asked every other names of people </s> \n",
      "Trigram\n",
      "<s> Why do we have that same thing I thought I’d do and go directly against whoever they happen to believe </s> \n",
      "Quadgram\n",
      "<s> He’s doing a tremendous job </s> \n"
     ]
    }
   ],
   "source": [
    "MLE=[MLEU,MLEB,MLET,MLEQ]\n",
    "gram=[uni,big,tri,quad]\n",
    "n=[uc,bc,tc,qc]\n",
    "print(\"Unigram\")\n",
    "generator(MLE,1,100)\n",
    "print()\n",
    "print(\"Bigram\")\n",
    "generator(MLE,2,100)\n",
    "print()\n",
    "print(\"Trigram\")\n",
    "generator(MLE,3,100)\n",
    "print()\n",
    "print(\"Quadgram\")\n",
    "generator(MLE,4,100)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity for classical approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log as log\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(gram,MLE,xTest,n):\n",
    "    ans=0\n",
    "    l=0\n",
    "    for i in xTest:\n",
    "        ngram = ngrams(sen.split(), n)\n",
    "        for x in ngram:\n",
    "            if(x not in gram[n-1]):\n",
    "                ans+=0\n",
    "                l+=len(x)\n",
    "            else:\n",
    "                ans+=log(1/gram[n-1][x],2)\n",
    "                l+=len(x)\n",
    "    return(math.pow(2,(-1*ans/l)))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For unigram  658.2817108218651\n",
      "For bigram  3.318241956119028\n",
      "For trigram  1.0958726911352492\n",
      "For quadgram  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"For unigram \",perplexity(gram,MLE,xTest,1))\n",
    "print(\"For bigram \",perplexity(gram,MLE,xTest,2))\n",
    "print(\"For trigram \",perplexity(gram,MLE,xTest,3))\n",
    "print(\"For quadgram \",perplexity(gram,MLE,xTest,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout,SimpleRNN \n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 2, 100)            652900    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2, 100)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 50)                7550      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 75)                3825      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 6529)              496204    \n",
      "=================================================================\n",
      "Total params: 1,160,479\n",
      "Trainable params: 1,160,479\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "135034/135034 [==============================] - 42s 314us/step - loss: 5.7881 - acc: 0.1312\n",
      "Epoch 2/10\n",
      "135034/135034 [==============================] - 39s 286us/step - loss: 5.1805 - acc: 0.1842\n",
      "Epoch 3/10\n",
      "135034/135034 [==============================] - 34s 251us/step - loss: 5.0078 - acc: 0.1975\n",
      "Epoch 4/10\n",
      "135034/135034 [==============================] - 37s 274us/step - loss: 4.9248 - acc: 0.2039\n",
      "Epoch 5/10\n",
      "135034/135034 [==============================] - 40s 295us/step - loss: 4.8768 - acc: 0.2077\n",
      "Epoch 6/10\n",
      "135034/135034 [==============================] - 44s 325us/step - loss: 4.8465 - acc: 0.2106\n",
      "Epoch 7/10\n",
      "135034/135034 [==============================] - 39s 286us/step - loss: 4.8275 - acc: 0.2137\n",
      "Epoch 8/10\n",
      "135034/135034 [==============================] - 38s 283us/step - loss: 4.8165 - acc: 0.2159\n",
      "Epoch 9/10\n",
      "135034/135034 [==============================] - 40s 295us/step - loss: 4.8080 - acc: 0.2180\n",
      "Epoch 10/10\n",
      "135034/135034 [==============================] - 40s 296us/step - loss: 4.8063 - acc: 0.2193\n"
     ]
    }
   ],
   "source": [
    "a = list()\n",
    "n = 3\n",
    "for i in xTrain:\n",
    "  grams = ngrams(i.split(),3)\n",
    "  for gram in grams:\n",
    "        a.append(list(gram))\n",
    "    \n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(a)\n",
    "b = t.texts_to_sequences(a)\n",
    "\n",
    "length = len(t.word_index) + 1\n",
    "\n",
    "b = np.array(b)\n",
    "\n",
    "x_train = b[:,:-1]\n",
    "y_train = b[:,-1]\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=length)\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(length, 100, input_length=n-1))\n",
    "model1.add(Dropout(0.15))\n",
    "model1.add(SimpleRNN(50))\n",
    "model1.add(Dense(75, activation='relu'))\n",
    "model1.add(Dense(length, activation='softmax'))\n",
    "\n",
    "model1.summary()\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "history_rnn = model1.fit(x_train, y_train, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 2, 100)            652900    \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 2, 50)             30200     \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 6529)              332979    \n",
      "=================================================================\n",
      "Total params: 1,038,829\n",
      "Trainable params: 1,038,829\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "135034/135034 [==============================] - 58s 431us/step - loss: 6.0992 - acc: 0.0985\n",
      "Epoch 2/10\n",
      "135034/135034 [==============================] - 45s 335us/step - loss: 5.6689 - acc: 0.1199\n",
      "Epoch 3/10\n",
      "135034/135034 [==============================] - 42s 311us/step - loss: 5.3662 - acc: 0.1516\n",
      "Epoch 4/10\n",
      "135034/135034 [==============================] - 40s 294us/step - loss: 5.2100 - acc: 0.1734\n",
      "Epoch 5/10\n",
      "135034/135034 [==============================] - 42s 309us/step - loss: 5.1296 - acc: 0.1805\n",
      "Epoch 6/10\n",
      "135034/135034 [==============================] - 45s 335us/step - loss: 5.0732 - acc: 0.1859\n",
      "Epoch 7/10\n",
      "135034/135034 [==============================] - 42s 310us/step - loss: 5.0354 - acc: 0.1917\n",
      "Epoch 8/10\n",
      "135034/135034 [==============================] - 43s 317us/step - loss: 5.0099 - acc: 0.1969\n",
      "Epoch 9/10\n",
      "135034/135034 [==============================] - 49s 365us/step - loss: 4.9924 - acc: 0.2007\n",
      "Epoch 10/10\n",
      "135034/135034 [==============================] - 47s 349us/step - loss: 4.9793 - acc: 0.2040\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(length, 100, input_length=n-1))\n",
    "model2.add(LSTM(50, return_sequences=True))\n",
    "model2.add(LSTM(50))\n",
    "model2.add(Dense(50, activation='relu'))\n",
    "model2.add(Dense(length, activation='softmax'))\n",
    "\n",
    "model2.summary()\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "history_lstm = model2.fit(x_train, y_train, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generators for RNN and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> We’re going to be a lot of people </s>\n",
      "<s> They have to be a lot of people </s>\n",
      "<s> I’ll have to be a lot of people </s>\n",
      "<s> No </s>\n",
      "<s> It’s a lot of people </s>\n"
     ]
    }
   ],
   "source": [
    "#LSTM\n",
    "import random\n",
    "for i in range(5):\n",
    "  result = list()\n",
    "  text = xTrain[random.randint(0,len(xTrain))].split(\" \")\n",
    "  f = 0\n",
    "  if(len(text)>=n):\n",
    "    result = text[:n-1]\n",
    "    l = n\n",
    "    while(result[-1]!=\"</s>\"):\n",
    "      encoded = t.texts_to_sequences(result)\n",
    "      encoded=[i[0] for i in encoded]\n",
    "      encoded = pad_sequences([encoded], maxlen= 2, padding='pre')\n",
    "      encoded = np.array(encoded)\n",
    "      yhat = model2.predict_classes(encoded, verbose=0)\n",
    "      ans = ''\n",
    "      for word, index in t.word_index.items():\n",
    "        if index == yhat:\n",
    "          ans = word\n",
    "          break\n",
    "      result.append(ans)\n",
    "      l+=1\n",
    "    print(\" \".join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> THAT'S going to be a lot of people </s>\n",
      "<s> And i don’t know </s>\n",
      "<s> In the world </s>\n",
      "<s> I think it’s going to be a lot of people </s>\n",
      "<s> But i don’t know </s>\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "import random\n",
    "for i in range(5):\n",
    "  result = list()\n",
    "  text = xTrain[random.randint(0,len(xTrain))].split(\" \")\n",
    "  f = 0\n",
    "  if(len(text)>=n):\n",
    "    result = text[:n-1]\n",
    "    l = n\n",
    "    while(result[-1]!=\"</s>\"):\n",
    "      encoded = t.texts_to_sequences(result)\n",
    "      encoded=[i[0] for i in encoded]\n",
    "      encoded = pad_sequences([encoded], maxlen= 2, padding='pre')\n",
    "      encoded = np.array(encoded)\n",
    "      yhat = model1.predict_classes(encoded, verbose=0)\n",
    "      ans = ''\n",
    "      for word, index in t.word_index.items():\n",
    "        if index == yhat:\n",
    "          ans = word\n",
    "          break\n",
    "      result.append(ans)\n",
    "      l+=1\n",
    "    print(\" \".join(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks essentially learns the patterns of the language while in n-grams approach we use probability to generate the most fitting word to a set of words. LSTM here gives a lower accuracy than RNN but it could be trained in a better way than this. Neural networks will give a better result than classical approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
